{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайные леса\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным пользователей социальной сети Вконтакте, и сравнить его эффективность с ансамблем, предоставляемым библиотекой CatBoost.\n",
    "\n",
    "В результате мы сможем определить, какие подписки пользователей больше всего влияют на определение возраста и пола человека. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import gini, entropy, gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (2 балла)\n",
    "Random Forest состоит из деревьев решений. Каждое такое дерево строится на одной из выборок, полученных при помощи bagging. Элементы, которые не вошли в новую обучающую выборку, образуют out-of-bag выборку. Кроме того, в каждом узле дерева мы случайным образом выбираем набор из `max_features` и ищем признак для предиката разбиения только в этом наборе.\n",
    "\n",
    "Сегодня мы будем работать только с бинарными признаками, поэтому нет необходимости выбирать значение признака для разбиения.\n",
    "\n",
    "#### Методы\n",
    "`predict(X)` - возвращает предсказанные метки для элементов выборки `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`X, y` - обучающая выборка и соответствующие ей метки классов. Из нее нужно получить выборку для построения дерева при помощи bagging. Out-of-bag выборку нужно запомнить, она понадобится потом.\n",
    "\n",
    "`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n",
    "\n",
    "`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n",
    "\n",
    "`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n",
    "\n",
    "`max_features=\"auto\"` - количество признаков, которые могут использоваться в узле. Если `\"auto\"` - равно `sqrt(X.shape[1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание.\n",
    "\n",
    "#### Параметры конструктора\n",
    "`n_estimators` - количество используемых для предсказания деревьев.\n",
    "\n",
    "Остальное - параметры деревьев.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n",
    "\n",
    "`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", n_estimators=10):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_forest = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            self.random_forest.append(DecisionTree(X, y,\n",
    "                                                   criterion=self.criterion,\n",
    "                                                   max_depth=self.max_depth,\n",
    "                                                   min_samples_leaf=self.min_samples_leaf,\n",
    "                                                   max_features=self.max_features))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted_matrix = []\n",
    "        for tree in self.random_forest:\n",
    "            predicted_matrix.append(tree.predict(X))\n",
    "\n",
    "        predicted_matrix = np.array(predicted_matrix)\n",
    "        unique_values, indexes = np.unique(predicted_matrix, return_inverse=True)\n",
    "        return unique_values[\n",
    "            np.argmax(\n",
    "                np.apply_along_axis(np.bincount, 0, indexes.reshape(predicted_matrix.shape), None, np.max(indexes) + 1),\n",
    "                axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 (2 балла)\n",
    "Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest - посчитать out-of-bag ошибку предсказания `err_oob`, а затем перемешать значения признака `j` и посчитать ее (`err_oob_j`) еще раз. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n",
    "\n",
    "Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(y, y_pred):\n",
    "    return np.mean(y == y_pred)\n",
    "\n",
    "def tree_feature_importance(tree):\n",
    "    X = tree.X_out_bag\n",
    "    y = tree.y_out_bag\n",
    "    y_pred = tree.predict(X)\n",
    "    accuracy = count_accuracy(y, y_pred)\n",
    "    importance = []\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        X_shuffle = copy.deepcopy(X)\n",
    "        np.random.shuffle(X_shuffle[:, i])\n",
    "\n",
    "        y_pred_shuffle = tree.predict(X_shuffle)\n",
    "        accuracy_shuffle = count_accuracy(y, y_pred_shuffle)\n",
    "        importance.append(accuracy - accuracy_shuffle)\n",
    "\n",
    "    return np.array(importance)\n",
    "\n",
    "def feature_importance(rfc):\n",
    "    importance_matrix = []\n",
    "    for tree in rfc.random_forest:\n",
    "        importance_matrix.append(tree_feature_importance(tree))\n",
    "\n",
    "    return np.mean(np.array(importance_matrix), axis=0)\n",
    "\n",
    "def most_important_features(importance, names, k=20):\n",
    "    # Выводит названия k самых важных признаков\n",
    "    idicies = np.argsort(importance)[::-1][:k]\n",
    "    return np.array(names)[idicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, пришло время протестировать наше дерево на простом синтетическом наборе данных. В результате точность должна быть примерно равна `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Importance: [-1.24542340e-03 -1.29356867e-03  1.78894568e-01  1.66369467e-01\n",
      "  3.37730586e-01 -2.62198624e-04]\n"
     ]
    }
   ],
   "source": [
    "def synthetic_dataset(size):\n",
    "    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n",
    "          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n",
    "    y = [i % 3 for i in range(size)]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = synthetic_dataset(1000)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X, y)\n",
    "print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n",
    "print(\"Importance:\", feature_importance(rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 (3 балла)\n",
    "Теперь поработаем с реальными данными.\n",
    "\n",
    "Выборка состоит из публичных анонимизированных данных пользователей социальной сети Вконтакте. Первые два столбца отражают возрастную группу (`zoomer`, `doomer` и `boomer`) и пол (`female`, `male`). Все остальные столбцы являются бинарными признаками, каждый из них определяет, подписан ли пользователь на определенную группу/публичную страницу или нет.\\\n",
    "\\\n",
    "Необходимо обучить два классификатора, один из которых определяет возрастную группу, а второй - пол.\\\n",
    "\\\n",
    "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются. Лес должен строиться за какое-то разумное время.\n",
    "\n",
    "Оценка:\n",
    "1. 1 балл за исправно работающий код\n",
    "2. +1 балл за точность предсказания возростной группы выше 65%\n",
    "3. +1 балл за точность предсказания пола выше 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    dataframe = pandas.read_csv(path, header=0)\n",
    "    dataset = dataframe.values.tolist()\n",
    "    random.shuffle(dataset)\n",
    "    y_age = [row[0] for row in dataset]\n",
    "    y_sex = [row[1] for row in dataset]\n",
    "    X = [row[2:] for row in dataset]\n",
    "    \n",
    "    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6582597730138714\n",
      "Most important features:\n",
      "1. ovsyanochan\n",
      "2. rhymes\n",
      "3. mudakoff\n",
      "4. 4ch\n",
      "5. iwantyou\n",
      "6. dayvinchik\n",
      "7. styd.pozor\n",
      "8. pozor\n",
      "9. pixel_stickers\n",
      "10. pravdashowtop\n",
      "11. top_screens\n",
      "12. memeboizz\n",
      "13. pustota_diary\n",
      "14. rapnewrap\n",
      "15. girlmeme\n",
      "16. femalemem\n",
      "17. reflexia_our_feelings\n",
      "18. bot_maxim\n",
      "19. i_d_t\n",
      "20. tumblr_vacuum\n"
     ]
    }
   ],
   "source": [
    "from task import rfc_age\n",
    "\n",
    "rfc_age.fit(X_train, y_age_train)\n",
    "print(\"Accuracy:\", np.mean(rfc_age.predict(X_test) == y_age_test))\n",
    "print(\"Most important features:\")\n",
    "for i, name in enumerate(most_important_features(feature_importance(rfc_age), features, 20)):\n",
    "    print(str(i+1) + \".\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8423707440100883\n",
      "Most important features:\n",
      "1. 40kg\n",
      "2. girlmeme\n",
      "3. zerofat\n",
      "4. modnailru\n",
      "5. i_d_t\n",
      "6. 9o_6o_9o\n",
      "7. be.women\n",
      "8. rapnewrap\n",
      "9. mudakoff\n",
      "10. sh.cook\n",
      "11. 4ch\n",
      "12. reflexia_our_feelings\n",
      "13. recipes40kg\n",
      "14. thesmolny\n",
      "15. cook_good\n",
      "16. psy.people\n",
      "17. woman.blog\n",
      "18. bot_maxim\n",
      "19. combovine\n",
      "20. beauty\n"
     ]
    }
   ],
   "source": [
    "from task import rfc_gender\n",
    "\n",
    "rfc_gender = RandomForestClassifier(n_estimators=10)\n",
    "rfc_gender.fit(X_train, y_sex_train)\n",
    "print(\"Accuracy:\", np.mean(rfc_gender.predict(X_test) == y_sex_test))\n",
    "print(\"Most important features:\")\n",
    "for i, name in enumerate(most_important_features(feature_importance(rfc_gender), features, 20)):\n",
    "    print(str(i+1) + \".\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "В качестве аьтернативы попробуем CatBoost. \n",
    "\n",
    "Устаниовить его можно просто с помощью `pip install catboost`. Туториалы можно найти, например, [здесь](https://catboost.ai/docs/concepts/python-usages-examples.html#multiclassification) и [здесь](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb). Главное - не забудьте использовать `loss_function='MultiClass'`.\\\n",
    "\\\n",
    "Сначала протестируйте CatBoost на синтетических данных. Выведите точность и важность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9255685\ttotal: 2.1ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.7872102\ttotal: 4.66ms\tremaining: 18.6ms\n",
      "2:\tlearn: 0.6825833\ttotal: 6.48ms\tremaining: 15.1ms\n",
      "3:\tlearn: 0.5969569\ttotal: 8.35ms\tremaining: 12.5ms\n",
      "4:\tlearn: 0.5255767\ttotal: 10.2ms\tremaining: 10.2ms\n",
      "5:\tlearn: 0.4652426\ttotal: 12ms\tremaining: 8.02ms\n",
      "6:\tlearn: 0.4114182\ttotal: 13.8ms\tremaining: 5.91ms\n",
      "7:\tlearn: 0.3652614\ttotal: 15.6ms\tremaining: 3.89ms\n",
      "8:\tlearn: 0.3253697\ttotal: 17.3ms\tremaining: 1.92ms\n",
      "9:\tlearn: 0.2923496\ttotal: 19.1ms\tremaining: 0us\n",
      "Accuracy: 0.3344888888888889\n"
     ]
    }
   ],
   "source": [
    "X, y = synthetic_dataset(1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "catboost_synthetic = CatBoostClassifier(loss_function='MultiClass',\n",
    "                                        iterations=10,\n",
    "                                        learning_rate=0.1,\n",
    "                                        depth=4)\n",
    "catboost_synthetic.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(catboost_synthetic.predict(X_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 (3 балла)\n",
    "Попробуем применить один из используемых на практике алгоритмов. В этом нам поможет CatBoost. Также, как и реализованный ними RandomForest, применим его для определения пола и возраста пользователей сети Вконтакте, выведите названия наиболее важных признаков так же, как в задании 3.\\\n",
    "\\\n",
    "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются.\n",
    "\n",
    "Оценка:\n",
    "1. 1 балл за исправно работающий код\n",
    "2. +1 балл за точность предсказания возростной группы выше 65%\n",
    "3. +1 балл за точность предсказания пола выше 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
    "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n",
    "X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0021309\ttotal: 169ms\tremaining: 1.52s\n",
      "1:\tlearn: 0.9359616\ttotal: 175ms\tremaining: 701ms\n",
      "2:\tlearn: 0.8973860\ttotal: 179ms\tremaining: 418ms\n",
      "3:\tlearn: 0.8678255\ttotal: 183ms\tremaining: 275ms\n",
      "4:\tlearn: 0.8414548\ttotal: 188ms\tremaining: 188ms\n",
      "5:\tlearn: 0.8233869\ttotal: 192ms\tremaining: 128ms\n",
      "6:\tlearn: 0.8079535\ttotal: 196ms\tremaining: 84ms\n",
      "7:\tlearn: 0.7910472\ttotal: 200ms\tremaining: 50ms\n",
      "8:\tlearn: 0.7803472\ttotal: 203ms\tremaining: 22.6ms\n",
      "9:\tlearn: 0.7665295\ttotal: 205ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "catboost_age = CatBoostClassifier(loss_function='MultiClass',\n",
    "                                  iterations=10,\n",
    "                                  learning_rate=1,\n",
    "                                  depth=2)\n",
    "catboost_age.fit(X_train, y_age_train)\n",
    "catboost_age.save_model('catboost_age.cbm', format='cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6139866\ttotal: 1.99ms\tremaining: 17.9ms\n",
      "1:\tlearn: 0.5689612\ttotal: 5.31ms\tremaining: 21.3ms\n",
      "2:\tlearn: 0.5379372\ttotal: 7.04ms\tremaining: 16.4ms\n",
      "3:\tlearn: 0.5165357\ttotal: 8.76ms\tremaining: 13.1ms\n",
      "4:\tlearn: 0.4952735\ttotal: 10.5ms\tremaining: 10.5ms\n",
      "5:\tlearn: 0.4729781\ttotal: 12.2ms\tremaining: 8.11ms\n",
      "6:\tlearn: 0.4562936\ttotal: 13.9ms\tremaining: 5.95ms\n",
      "7:\tlearn: 0.4438425\ttotal: 15.6ms\tremaining: 3.91ms\n",
      "8:\tlearn: 0.4321296\ttotal: 17.4ms\tremaining: 1.93ms\n",
      "9:\tlearn: 0.4239501\ttotal: 20ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "catboost_gender = CatBoostClassifier(loss_function='MultiClass',\n",
    "                                  iterations=10,\n",
    "                                  learning_rate=1,\n",
    "                                  depth=2)\n",
    "catboost_gender.fit(X_train, y_sex_train)\n",
    "catboost_gender.save_model('catboost_gender.cbm', format='cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.331483392674553\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", np.mean(catboost_age.predict(X_test) == y_age_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пол"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89281210592686\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", np.mean(rfc_gender.predict(X_test) == y_sex_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
